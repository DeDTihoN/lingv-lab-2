{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xgwPITM_L7nf",
    "outputId": "3532b597-3630-4161-be2c-de778a8c8a86"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: wikipedia-api in /usr/local/lib/python3.10/dist-packages (0.7.1)\n",
      "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.9.0.post1)\n",
      "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.2.1)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
      "Requirement already satisfied: rouge-score in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
      "Requirement already satisfied: cohere in /usr/local/lib/python3.10/dist-packages (5.11.4)\n",
      "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (2.151.0)\n",
      "Requirement already satisfied: rake-nltk in /usr/local/lib/python3.10/dist-packages (1.0.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from wikipedia-api) (2.32.3)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.6)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.5.1+cu121)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.26.2)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (11.0.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.2)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.4.0)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.16.0)\n",
      "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in /usr/local/lib/python3.10/dist-packages (from cohere) (1.9.7)\n",
      "Requirement already satisfied: httpx>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from cohere) (0.27.2)\n",
      "Requirement already satisfied: httpx-sse==0.4.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (0.4.0)\n",
      "Requirement already satisfied: parameterized<0.10.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (0.9.0)\n",
      "Requirement already satisfied: pydantic>=1.9.2 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.9.2)\n",
      "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.23.4)\n",
      "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.32.0.20241016)\n",
      "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (4.12.2)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (0.22.0)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (2.27.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (0.2.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (2.19.2)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (4.1.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.66.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (4.25.5)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.25.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (4.9)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client) (3.2.0)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (3.7.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (1.0.7)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (3.10)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.21.2->cohere) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.2->cohere) (0.7.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->wikipedia-api) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->wikipedia-api) (2.2.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (0.6.1)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.21.2->cohere) (1.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install wikipedia-api faiss-cpu sentence-transformers transformers datasets nltk rouge-score cohere google-api-python-client rake-nltk"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import wikipediaapi\n",
    "import faiss\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from datasets import load_dataset\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from rouge_score import rouge_scorer\n",
    "import cohere\n",
    "import os\n",
    "import spacy\n",
    "from googleapiclient.discovery import build\n",
    "from rake_nltk import Rake\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rDEZtISTMaa3",
    "outputId": "77656b7f-e7a9-4790-857c-3bd93356af40"
   },
   "execution_count": 334,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 334
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Налаштування Wikipedia API\n",
    "wiki = wikipediaapi.Wikipedia(\n",
    "    language='en',\n",
    "    user_agent='MyNLPApp/1.0 (myemail@example.com)'\n",
    ")\n",
    "\n",
    "# Налаштування Google Search API\n",
    "api_key = \"MY API KEY\"\n",
    "cse_id = \"MY CSE ID\"\n",
    "\n",
    "def google_search(query, api_key, cse_id, num_results=1):\n",
    "    \"\"\"\n",
    "    Выполняет поиск в Google и возвращает результаты.\n",
    "    \"\"\"\n",
    "    service = build(\"customsearch\", \"v1\", developerKey=api_key)\n",
    "    res = service.cse().list(q=query, cx=cse_id, num=num_results).execute()\n",
    "    return [item['snippet'] for item in res.get('items', [])]\n",
    "\n",
    "# Завантажуємо модель SpaCy для визначення сутностей\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def extract_main_topics(context):\n",
    "    \"\"\"\n",
    "    Витягує ключові сутності та ключові слова з тексту для використання в запиті до Wikipedia або Google.\n",
    "    \"\"\"\n",
    "    doc = nlp(context)\n",
    "    topics = [ent.text for ent in doc.ents if ent.label_ in [\"PERSON\", \"ORG\", \"GPE\", \"LOC\", \"EVENT\", \"WORK_OF_ART\"]]\n",
    "\n",
    "    # Використовуємо RAKE для виділення ключових слів\n",
    "    rake = Rake()\n",
    "    rake.extract_keywords_from_text(context)\n",
    "    keywords = rake.get_ranked_phrases()\n",
    "\n",
    "    # Об'єднуємо сутності та ключові слова, щоб отримати розширений набір тем\n",
    "    topics.extend(keywords)\n",
    "\n",
    "    # Видаляємо дублікати та залишаємо унікальні теми\n",
    "    topics = list(set(topics))\n",
    "\n",
    "    # Якщо досі немає тем, використовуємо весь контекст як запит\n",
    "    if not topics:\n",
    "        topics = [context]\n",
    "\n",
    "    return topics\n",
    "\n",
    "def fetch_wikipedia_article(query):\n",
    "    \"\"\"\n",
    "    Отримує текст статті з Wikipedia на основі запиту.\n",
    "    \"\"\"\n",
    "    page = wiki.page(query)\n",
    "    if page.exists():\n",
    "        return page.summary[:500]  # Обмежуємо текст до 500 символів\n",
    "    return None\n",
    "\n",
    "def get_relevant_content(context):\n",
    "    \"\"\"\n",
    "    Знаходить статті в Wikipedia або Google, релевантні основним темам контексту.\n",
    "    Повертає список знайдених статей.\n",
    "    \"\"\"\n",
    "    topics = extract_main_topics(context)\n",
    "    content = []\n",
    "    for topic in topics:\n",
    "        wikipedia_content = fetch_wikipedia_article(topic)\n",
    "        if wikipedia_content:\n",
    "            content.append(wikipedia_content)\n",
    "        google_results = google_search(topic, api_key, cse_id, num_results=5)\n",
    "        for google_result in google_results:\n",
    "            content.append(google_result[:500])\n",
    "    # Також додаємо результати пошуку за всім контекстом\n",
    "    google_results_full_context = google_search(context, api_key, cse_id, num_results=5)\n",
    "    for google_result in google_results_full_context:\n",
    "        content.append(google_result[:500])\n",
    "    return content"
   ],
   "metadata": {
    "id": "pN4zHIkTMdLv"
   },
   "execution_count": 335,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Завантажуємо датасет CNN/Daily Mail\n",
    "dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\", split=\"train[:100]\")  # Використовуємо перші 100 текстів для тесту\n",
    "\n",
    "# Створюємо корпус з перших 100 статей\n",
    "cnn_corpus = [item['article'][:500] for item in dataset]\n",
    "\n",
    "# Об'єднуємо статті з CNN/Daily Mail\n",
    "full_corpus = cnn_corpus"
   ],
   "metadata": {
    "id": "SUdJz9I6Me_X"
   },
   "execution_count": 336,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def prepare_faiss_index(corpus):\n",
    "    embeddings = embedder.encode(corpus, convert_to_tensor=True)\n",
    "    index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "    index.add(embeddings.cpu().numpy())\n",
    "    return index, corpus\n",
    "\n",
    "# Підготовка початкового індексу\n",
    "index, full_corpus = prepare_faiss_index(full_corpus)\n"
   ],
   "metadata": {
    "id": "AsRz0QvKSm5j"
   },
   "execution_count": 337,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def update_corpus_with_content(context, corpus, index):\n",
    "    \"\"\"\n",
    "    Витягує статті з Wikipedia або Google на основі ключових тем контексту і додає їх у корпус.\n",
    "    Кожну знайдену статтю додає окремо.\n",
    "    \"\"\"\n",
    "    relevant_content_list = get_relevant_content(context)\n",
    "    for relevant_content in relevant_content_list:\n",
    "        if relevant_content != \"No relevant information found.\":\n",
    "            if relevant_content not in corpus:\n",
    "                corpus.append(relevant_content)\n",
    "                index.add(embedder.encode([relevant_content]))\n",
    "    return corpus\n",
    "\n",
    "def retrieve_documents(context, index, corpus, k=10):\n",
    "    \"\"\"\n",
    "    Витягує топ-K релевантних документів і скорочує їх до заданої кількості слів.\n",
    "    \"\"\"\n",
    "    context_embedding = embedder.encode(context, convert_to_tensor=True).numpy()\n",
    "    distances, indices = index.search(context_embedding.reshape(1, -1), k)\n",
    "    retrieved_docs = [corpus[i] for i in indices[0]]\n",
    "    # Скорочуємо кожен документ до 100 слів\n",
    "    shortened_docs = [\"\".join(doc[:500]) for doc in retrieved_docs]\n",
    "    return shortened_docs"
   ],
   "metadata": {
    "id": "Hnv9cT99MgQa"
   },
   "execution_count": 338,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Налаштування API ключа для Cohere\n",
    "co = cohere.ClientV2('Cohere API-KEY')\n",
    "\n",
    "def generate_completion_cohere(context, retrieved_info=None):\n",
    "    \"\"\"\n",
    "    Генерація тексту на основі контексту і витягнутої інформації (якщо є) з використанням Cohere.\n",
    "    \"\"\"\n",
    "    if retrieved_info:\n",
    "        prompt = f\"Additional information: {retrieved_info}\\nComplete the text:{context}\\n\"\n",
    "    else:\n",
    "        prompt = f\"Complete the text: {context}\\n\"\n",
    "\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    response = co.chat(\n",
    "        model=\"command-r\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return response.message.content[0].text"
   ],
   "metadata": {
    "id": "0GDBifpYRXZ6"
   },
   "execution_count": 339,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def rag_text_completion(context, index, corpus):\n",
    "    \"\"\"\n",
    "    Повний пайплайн RAG для доповнення тексту.\n",
    "    \"\"\"\n",
    "    # Оновлення корпусу з Wikipedia або Google\n",
    "    corpus = update_corpus_with_content(context, corpus, index)\n",
    "\n",
    "    # Витягування релевантної інформації\n",
    "    retrieved_docs = retrieve_documents(context, index, corpus, k=3)\n",
    "    retrieved_info = \";\".join(retrieved_docs)\n",
    "\n",
    "    # Генерація тексту з використанням RAG\n",
    "    completed_text = generate_completion_cohere(context, retrieved_info)\n",
    "    return completed_text"
   ],
   "metadata": {
    "id": "FxBbJf8k1OPC"
   },
   "execution_count": 340,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "context = \"US Dollar to Ukranian Hryvnia course is : \"\n",
    "\n",
    "# Генерація тексту без використання RAG\n",
    "generated_text_without_rag = generate_completion_cohere(context)\n",
    "\n",
    "# Генерація тексту з використанням RAG\n",
    "generated_text_with_rag = rag_text_completion(context, index, full_corpus)\n",
    "\n",
    "documents = retrieve_documents(context,index,full_corpus)\n",
    "\n",
    "for document in documents:\n",
    "    print(document)\n",
    "\n",
    "print(\"Generated Text without RAG:\")\n",
    "print(generated_text_without_rag)\n",
    "print(\"\\nGenerated Text with RAG:\")\n",
    "print(generated_text_with_rag)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0DunsnvP1SIC",
    "outputId": "c51035b1-73ef-418b-a67a-5e8c24b97ed1"
   },
   "execution_count": 341,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Prompt: Complete the text: US Dollar to Ukranian Hryvnia course is : \n",
      "\n",
      "Prompt: Additional information: Convert US Dollar to Ukrainian Hryvnia. USD. UAH. 1 USD. 41.3354 UAH. 5 USD. 206.677 UAH. 10 USD. 413.354 UAH. 25 USD. 1,033.38 UAH. 50 USD. 2,066.77 UAH. 100 ...;Get the latest 1 US Dollar to Ukrainian Hryvnia rate for FREE with the original Universal Currency Converter. Set rate alerts for to and learn more about US ...;Get the latest 1 Ukrainian Hryvnia to US Dollar rate for FREE with the original Universal Currency Converter. Set rate alerts for to and learn more about ...\n",
      "Complete the text:US Dollar to Ukranian Hryvnia course is : \n",
      "\n",
      "Convert US Dollar to Ukrainian Hryvnia. USD. UAH. 1 USD. 41.3354 UAH. 5 USD. 206.677 UAH. 10 USD. 413.354 UAH. 25 USD. 1,033.38 UAH. 50 USD. 2,066.77 UAH. 100 ...\n",
      "Get the latest 1 US Dollar to Ukrainian Hryvnia rate for FREE with the original Universal Currency Converter. Set rate alerts for to and learn more about US ...\n",
      "Get the latest 1 Ukrainian Hryvnia to US Dollar rate for FREE with the original Universal Currency Converter. Set rate alerts for to and learn more about ...\n",
      "The hryvnia has been the national currency of Ukraine since 2 September 1996. The hryvnia is divided into 100 kopiyok. It is named after a measure of weight ...\n",
      "Convert USD to UAH with the Wise Currency Converter. Analyze historical currency charts or live US dollar / Ukrainian hryvnia rates and get free rate alerts ...\n",
      "Official hryvnia exchange rate against foreign currencies (period average) Average weighted rates in the cash foreign exchange market of Ukraine.\n",
      "View live U.S. DOLLAR / UKRAINIAN HRYVNIA chart to track latest price changes. Trade ideas, forecasts and market news are at your disposal as well.\n",
      "Feb 24, 2022 ... But have you seen the Ukrainian hryvnia (UAH) ? The currency ... Of course I know how to create the order. But I would like to know ...\n",
      "UAH/USD reference rate as of 12 p.m. · Official hryvnia exchange rate against foreign currencies (period average) · Average weighted rates in the cash foreign ...\n",
      "U.S. Currency Education Program. Last Update: November 27, 2024. Back to Top. Board of Governors of the Federal Reserve System. About the Fed · News & Events ...\n",
      "Generated Text without RAG:\n",
      "1 US Dollar (USD) is equivalent to 46.61 Ukrainian Hryvnia (UAH).\n",
      "\n",
      "Generated Text with RAG:\n",
      "1 USD is equivalent to 41.3354 UAH.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Цільовий текст для порівняння\n",
    "reference = \"1 USD equals to 41.3354 UAH\"\n",
    "\n",
    "# Оцінка BLEU\n",
    "bleu_without_rag = sentence_bleu([reference.split()], generated_text_without_rag.split())\n",
    "bleu_with_rag = sentence_bleu([reference.split()], generated_text_with_rag.split())\n",
    "\n",
    "print(f\"BLEU Score without RAG: {bleu_without_rag}\")\n",
    "print(f\"BLEU Score with RAG: {bleu_with_rag}\")\n",
    "\n",
    "# Оцінка ROUGE\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
    "rouge_without_rag = scorer.score(reference, generated_text_without_rag)\n",
    "rouge_with_rag = scorer.score(reference, generated_text_with_rag)\n",
    "\n",
    "print(\"\\nROUGE Score without RAG:\")\n",
    "print(rouge_without_rag)\n",
    "print(\"\\nROUGE Score with RAG:\")\n",
    "print(rouge_with_rag)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bVQ_02HT5QHV",
    "outputId": "f2d37b64-5a92-4f76-dfb6-be91d4bc0e78"
   },
   "execution_count": 342,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "BLEU Score without RAG: 1.1896457329133973e-231\n",
      "BLEU Score with RAG: 9.85444998995587e-155\n",
      "\n",
      "ROUGE Score without RAG:\n",
      "{'rouge1': Score(precision=0.3333333333333333, recall=0.5714285714285714, fmeasure=0.4210526315789474), 'rougeL': Score(precision=0.3333333333333333, recall=0.5714285714285714, fmeasure=0.4210526315789474)}\n",
      "\n",
      "ROUGE Score with RAG:\n",
      "{'rouge1': Score(precision=0.75, recall=0.8571428571428571, fmeasure=0.7999999999999999), 'rougeL': Score(precision=0.75, recall=0.8571428571428571, fmeasure=0.7999999999999999)}\n"
     ]
    }
   ]
  }
 ]
}
